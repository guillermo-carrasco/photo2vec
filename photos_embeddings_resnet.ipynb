{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tduPrLvDS5Zc"
   },
   "source": [
    "# Photos similarity using Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xKbvzjSqh3CC",
    "outputId": "89f44f7f-8164-417f-8885-e95f1ac89eed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "import pickle\n",
    "\n",
    "from sklearn.cluster import KMeans, MeanShift\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = models.ResNet50_Weights.DEFAULT.transforms()\n",
    "        self.image_paths = self._get_image_paths(image_dir)\n",
    "\n",
    "    def _get_image_paths(self, image_dir):\n",
    "        image_paths = []\n",
    "        for root, _, files in os.walk(image_dir):\n",
    "            for file in files:\n",
    "                # Skip metadata files\n",
    "                if file.endswith('.jpeg'):\n",
    "                    image_paths.append(os.path.join(root, file))\n",
    "        return image_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path)\n",
    "        image = self.transform(image)\n",
    "        return image, image_path\n",
    "\n",
    "# Load the pre-trained ResNet50 model\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "\n",
    "# Remove the final classification layer\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "\n",
    "# Move the model to the GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "def generate_image_embeddings(data_loader, model, device):\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for images, paths in data_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = outputs.cpu().squeeze()\n",
    "            for i, path in enumerate(paths):\n",
    "                embeddings.append((path, outputs[i].flatten()))\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "images_path = '/content/images'\n",
    "dataset = ImageDataset(images_path)\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yBY4j9r2rx2M",
    "outputId": "f652c462-80c5-4e9d-d449-4ca7327024d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34040"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UQfcCmDdrVZA",
    "outputId": "3909cee9-b256-4210-9f2a-5c8d1ac17f99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 33s, sys: 6.02 s, total: 1min 39s\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Generate embeddings for all images in the directory\n",
    "embeddings = generate_image_embeddings(data_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y6lvC0H9uobf",
    "outputId": "7b30cd3c-64a6-4074-d5b4-9a859214a4bb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/content/images/Takeout 7/preprocessed/images/IMG_20160501_035208.jpeg',\n",
       "  tensor([0.0000, 0.0000, 0.0301,  ..., 0.4376, 0.0000, 0.0992])),\n",
       " ('/content/images/Takeout 7/preprocessed/images/IMG_20160121_185531.jpeg',\n",
       "  tensor([0.0000, 0.0086, 0.0815,  ..., 0.0000, 0.0000, 0.0000]))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = [(k, v) for k, v in embeddings]\n",
    "embeddings[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDmuNQabdwYk"
   },
   "source": [
    "## Finding similar pictures using Voyager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AEuhR9-mds8m"
   },
   "outputs": [],
   "source": [
    "from voyager import Index, Space\n",
    "\n",
    "# Create an empty Index object that can store vectors:\n",
    "index = Index(\n",
    "    Space.Cosine,\n",
    "    num_dimensions=len(embeddings[0][1]),\n",
    "    M=50,\n",
    "    ef_construction=1000\n",
    ")\n",
    "# IDs must be ints\n",
    "id_to_filename = {i: e[0] for i, e in enumerate(embeddings)}\n",
    "filename_to_id = {e[0]: i for i, e in enumerate(embeddings)}\n",
    "\n",
    "index.add_items(\n",
    "    vectors=[e[1] for e in embeddings],\n",
    "    ids=[filename_to_id[e[0]] for e in embeddings]\n",
    ")\n",
    "\n",
    "# Save the index to disk to reload later\n",
    "index.save(\"photo_embeddings.voy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "D7trAUUqfTJ3"
   },
   "outputs": [],
   "source": [
    "def find_k_nearest_neighbors(filename, k=10):\n",
    "    neighbors, distances = index.query(index.get_vector(filename_to_id[filename]), k=k)\n",
    "\n",
    "    print(f\"{k} closest neighbors to {filename} are:\")\n",
    "    for n, d in zip(neighbors, distances):\n",
    "        print(f\"File: {id_to_filename[n]} Distance: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uLUTEqvGf9YW",
    "outputId": "b49b5a77-1b1b-47c9-ccc4-432332adb9b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 closest neighbors to /content/images/Takeout 2/preprocessed/images/MVIMG_20190706_132654.jpeg are:\n",
      "File: /content/images/Takeout 2/preprocessed/images/MVIMG_20190706_132654.jpeg Distance: 0.0\n",
      "File: /content/images/Takeout 3/preprocessed/images/MVIMG_20190706_113849.jpeg Distance: 0.1754932999610901\n",
      "File: /content/images/Takeout 5/preprocessed/images/20170415_145710.jpeg Distance: 0.19180971384048462\n",
      "File: /content/images/Takeout 4/preprocessed/images/20170415_145710.jpeg Distance: 0.19180971384048462\n",
      "File: /content/images/Takeout 6/preprocessed/images/20170415_145710.jpeg Distance: 0.19180971384048462\n",
      "File: /content/images/Takeout 5/preprocessed/images/20170415_121842.jpeg Distance: 0.20159876346588135\n",
      "File: /content/images/Takeout 4/preprocessed/images/20170415_121842.jpeg Distance: 0.20159876346588135\n",
      "File: /content/images/Takeout 6/preprocessed/images/20170415_121842.jpeg Distance: 0.20159876346588135\n",
      "File: /content/images/Takeout 5/preprocessed/images/20170415_142132.jpeg Distance: 0.20648622512817383\n",
      "File: /content/images/Takeout 6/preprocessed/images/20170415_142132.jpeg Distance: 0.20648622512817383\n",
      "CPU times: user 1.17 ms, sys: 0 ns, total: 1.17 ms\n",
      "Wall time: 1.11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "find_k_nearest_neighbors('/content/images/Takeout 2/preprocessed/images/MVIMG_20190706_132654.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XLsuFf5F0tRH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
